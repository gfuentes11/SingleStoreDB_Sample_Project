{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Step: Synthetic Data Generation for the Global Terrorism Project\n",
    "\n",
    "## Overview\n",
    "This preprocessing step involves generating synthetic data for the Global Terrorism project. The synthetic data mimics the structure and characteristics of the Global Terrorism Database (GTD), providing a foundation for testing and validating preprocessing, analysis, and machine learning models in the project. \n",
    "\n",
    "## Purpose\n",
    "Creating synthetic data allows us to:\n",
    "- Validate the project's data processing pipelines without handling real-world sensitive information.\n",
    "- Test and validate the improvement made by SingleStoreDB in using Shared Keys and \n",
    "\n",
    "## Data Generation Process\n",
    "The Python script provided uses Python libraries (Pandas, NumPy, and random) to create a DataFrame containing the following main fields:\n",
    "\n",
    "- **Event Details**: `eventid`, `iyear`, `imonth`, and `iday` represent unique identifiers and the dates for each synthetic incident.\n",
    "- **Categorical Fields**: Categorical variables such as `country_txt`, `region_txt`, `attacktype1_txt`, and `targtype1_txt` are generated with predefined lists to mirror real-world values in the GTD.\n",
    "- **Numerical Fields**: Numeric fields like `nkill`, `nwound`, and `propvalue` simulate counts and values associated with each incident, using Poisson and uniform distributions to generate plausible values.\n",
    "\n",
    "## Output\n",
    "The generated synthetic data is saved as a CSV file (`synthetic_global_terrorism_data.csv`), which can then be loaded and used in subsequent steps of the project for testing and model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7y/qbbxwvy123gf0q88fyxgbqsh0000gn/T/ipykernel_69924/1080153293.py:7: DtypeWarning: Columns (4,6,31,33,61,62,63,76,79,90,92,94,96,114,115,121) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nkill mean: 2.266900036326409\n",
      "nwound mean: 2.8833316821329107\n",
      "nkillus mean: 0.02967207159605033\n",
      "nkillter mean: 0.320833746133439\n",
      "nwoundus mean: 0.025076230419514987\n",
      "nwoundte mean: 0.06638376099424281\n",
      "nhostkid mean: 1.0126702112435741\n",
      "ransomamt mean: 23573.307391268445\n",
      "nreleased mean: 0.2793225675065773\n",
      "Synthetic data appended and saved as 'expanded_global_terrorism_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Load the existing dataset\n",
    "file_path = input('Please enter your csv file you wish to expand: ')\n",
    "original_df = pd.read_csv(file_path)\n",
    "\n",
    "# Number of new synthetic rows to add\n",
    "n_new_rows = 1000000\n",
    "\n",
    "# Fill missing values in numerical columns with 0, which are required for Poisson generation\n",
    "# and ensure all values are non-negative\n",
    "original_df['nkill'] = original_df['nkill'].fillna(0).apply(lambda x: max(x, 0))\n",
    "original_df['nwound'] = original_df['nwound'].fillna(0).apply(lambda x: max(x, 0))\n",
    "original_df['propvalue'] = original_df['propvalue'].fillna(0).apply(lambda x: max(x, 0))\n",
    "original_df['nkillus'] = original_df['nkillus'].fillna(0).apply(lambda x: max(x, 0))\n",
    "original_df['nkillter'] = original_df['nkillter'].fillna(0).apply(lambda x: max(x, 0))\n",
    "original_df['nwoundus'] = original_df['nwoundus'].fillna(0).apply(lambda x: max(x, 0))\n",
    "original_df['nwoundte'] = original_df['nwoundte'].fillna(0).apply(lambda x: max(x, 0))\n",
    "original_df['nhostkid'] = original_df['nhostkid'].fillna(0).apply(lambda x: max(x, 0))\n",
    "original_df['ransomamt'] = original_df['ransomamt'].fillna(0).apply(lambda x: max(x, 0))\n",
    "original_df['nreleased'] = original_df['nreleased'].fillna(0).apply(lambda x: max(x, 0))  # Added to ensure no NaN or negative values\n",
    "\n",
    "# Print means of columns used for Poisson distribution to verify they are non-negative\n",
    "print(\"nkill mean:\", original_df['nkill'].mean())\n",
    "print(\"nwound mean:\", original_df['nwound'].mean())\n",
    "print(\"nkillus mean:\", original_df['nkillus'].mean())\n",
    "print(\"nkillter mean:\", original_df['nkillter'].mean())\n",
    "print(\"nwoundus mean:\", original_df['nwoundus'].mean())\n",
    "print(\"nwoundte mean:\", original_df['nwoundte'].mean())\n",
    "print(\"nhostkid mean:\", original_df['nhostkid'].mean())\n",
    "print(\"ransomamt mean:\", original_df['ransomamt'].mean())\n",
    "print(\"nreleased mean:\", original_df['nreleased'].mean())\n",
    "\n",
    "# Create possible values for synthetic data generation based on your original dataset\n",
    "countries = original_df['country_txt'].unique()\n",
    "regions = original_df['region_txt'].unique()\n",
    "attack_types = original_df['attacktype1_txt'].unique()\n",
    "target_types = original_df['targtype1_txt'].unique()\n",
    "weapon_types = original_df['weaptype1_txt'].unique()\n",
    "success_values = [0, 1]\n",
    "yes_no = [0, 1]\n",
    "\n",
    "# Generate synthetic data \n",
    "synthetic_data = {\n",
    "    'eventid': [f\"EVT{str(i).zfill(5)}\" for i in range(len(original_df), len(original_df) + n_new_rows)],\n",
    "    'iyear': np.random.choice(original_df['iyear'], n_new_rows),\n",
    "    'imonth': np.random.choice(original_df['imonth'], n_new_rows),\n",
    "    'iday': np.random.choice(original_df['iday'], n_new_rows),\n",
    "    'approxdate': [None] * n_new_rows,\n",
    "    'extended': random.choices(yes_no, k=n_new_rows),\n",
    "    'resolution': [None] * n_new_rows,\n",
    "    'country': np.random.choice(original_df['country'], n_new_rows),\n",
    "    'country_txt': random.choices(countries, k=n_new_rows),\n",
    "    'region': np.random.choice(original_df['region'], n_new_rows),\n",
    "    'region_txt': random.choices(regions, k=n_new_rows),\n",
    "    'provstate': np.random.choice(original_df['provstate'], n_new_rows),\n",
    "    'city': np.random.choice(original_df['city'], n_new_rows),\n",
    "    'latitude': np.random.normal(original_df['latitude'].mean(), original_df['latitude'].std(), n_new_rows),\n",
    "    'longitude': np.random.normal(original_df['longitude'].mean(), original_df['longitude'].std(), n_new_rows),\n",
    "    'specificity': np.random.choice(original_df['specificity'], n_new_rows),\n",
    "    'vicinity': random.choices(yes_no, k=n_new_rows),\n",
    "    'location': np.random.choice(original_df['location'], n_new_rows),\n",
    "    'summary': ['Synthetic summary text.'] * n_new_rows,\n",
    "    'crit1': random.choices(yes_no, k=n_new_rows),\n",
    "    'crit2': random.choices(yes_no, k=n_new_rows),\n",
    "    'crit3': random.choices(yes_no, k=n_new_rows),\n",
    "    'doubtterr': random.choices(yes_no, k=n_new_rows),\n",
    "    'alternative': random.choices([None, 1, 2], k=n_new_rows),\n",
    "    'alternative_txt': [None] * n_new_rows,\n",
    "    'multiple': random.choices(yes_no, k=n_new_rows),\n",
    "    'success': random.choices(success_values, k=n_new_rows),\n",
    "    'suicide': random.choices(yes_no, k=n_new_rows),\n",
    "    'attacktype1': np.random.choice(original_df['attacktype1'], n_new_rows),\n",
    "    'attacktype1_txt': random.choices(attack_types, k=n_new_rows),\n",
    "    'targtype1': np.random.choice(original_df['targtype1'], n_new_rows),\n",
    "    'targtype1_txt': random.choices(target_types, k=n_new_rows),\n",
    "    'weaptype1': np.random.choice(original_df['weaptype1'], n_new_rows),\n",
    "    'weaptype1_txt': random.choices(weapon_types, k=n_new_rows),\n",
    "    'nkill': np.random.poisson(lam=original_df['nkill'].mean(), size=n_new_rows),\n",
    "    'nkillus': np.random.poisson(lam=original_df['nkillus'].mean(), size=n_new_rows),\n",
    "    'nkillter': np.random.poisson(lam=original_df['nkillter'].mean(), size=n_new_rows),\n",
    "    'nwound': np.random.poisson(lam=original_df['nwound'].mean(), size=n_new_rows),\n",
    "    'nwoundus': np.random.poisson(lam=original_df['nwoundus'].mean(), size=n_new_rows),\n",
    "    'nwoundte': np.random.poisson(lam=original_df['nwoundte'].mean(), size=n_new_rows),\n",
    "    'property': random.choices(yes_no, k=n_new_rows),\n",
    "    'propextent': np.random.choice(original_df['propextent'], n_new_rows),\n",
    "    'propextent_txt': np.random.choice(original_df['propextent_txt'], n_new_rows),\n",
    "    'propvalue': np.random.normal(original_df['propvalue'].mean(), original_df['propvalue'].std(), n_new_rows).astype(int),\n",
    "    'ishostkid': random.choices(yes_no, k=n_new_rows),\n",
    "    'nhostkid': np.random.poisson(lam=original_df['nhostkid'].mean(), size=n_new_rows),\n",
    "    'ransom': random.choices(yes_no, k=n_new_rows),\n",
    "    'ransomamt': np.random.normal(original_df['ransomamt'].mean(), original_df['ransomamt'].std(), n_new_rows).astype(int),\n",
    "    'hostkidoutcome': np.random.choice(original_df['hostkidoutcome'], n_new_rows),\n",
    "    'nreleased': np.random.poisson(lam=original_df['nreleased'].mean(), size=n_new_rows),\n",
    "}\n",
    "\n",
    "# Create synthetic DataFrame\n",
    "# Append synthetic data to the original data\n",
    "# Save the expanded dataset\n",
    "\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "\n",
    "\n",
    "expanded_df = pd.concat([original_df, synthetic_df], ignore_index=True)\n",
    "\n",
    "expanded_df.to_csv('/Users/gabrielfuentes/Project2024_Repo/SingleStoreDB Sample Project/data/processed/expanded_global_terrorism_data.csv', index=False)\n",
    "print(\"Synthetic data appended and saved as 'expanded_global_terrorism_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying `eventid` Column to Sequential Values\n",
    "\n",
    "### Background\n",
    "While attempting to load the dataset into SingleStoreDB, errors were encountered regarding the `eventid` column. The error message indicated that some values in the `eventid` column were \"out of range.\" \n",
    "\n",
    "### Solution\n",
    "To address this, we are modifying the `eventid` column to contain sequential integer values, starting from 1 up to the total number of rows in the dataset. This approach simplifies the data by:\n",
    "1. Ensuring the `eventid` values fit within standard integer ranges, eliminating \"out of range\" errors during loading.\n",
    "2. Maintaining a unique identifier for each event that doesn't impact other analysis columns.\n",
    "\n",
    "### Script Overview\n",
    "The following script will:\n",
    "1. Load the CSV file into a DataFrame.\n",
    "2. Replace the `eventid` column with sequential integers, starting from 1.\n",
    "3. Save the updated dataset to a new CSV file, which can be loaded into SingleStoreDB without causing range-related errors in the `eventid` column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as /Users/gabrielfuentes/Project2024_Repo/SingleStoreDB Sample Project/data/processed/expanded_global_terrorism_data_sequential_eventid.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/gabrielfuentes/Project2024_Repo/SingleStoreDB Sample Project/data/processed/expanded_global_terrorism_data.csv' \n",
    "df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)\n",
    "\n",
    "# Replace the 'eventid' column with sequential numbers\n",
    "df['eventid'] = range(1, len(df) + 1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_path = '/Users/gabrielfuentes/Project2024_Repo/SingleStoreDB Sample Project/data/processed/expanded_global_terrorism_data_sequential_eventid.csv'\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"File saved as {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SingleStore)",
   "language": "python",
   "name": "singlestore_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
